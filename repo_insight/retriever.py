import glob
from langchain_core.documents import Document
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
#from langchain_chroma import Chroma
from langchain.vectorstores import Chroma
from langchain.vectorstores.base import VectorStoreRetriever
from langchain.embeddings.base import Embeddings
import shutil
import os
from langchain.schema import Document
from repo_insight.utils.project_structure import get_project_structure
import gc
import time
from repo_insight.settings import get_shared_settings

def load_documents(local_path: str) -> list[Document]:
    """æŒ‡å®šãƒ‘ã‚¹é…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€Documentãƒªã‚¹ãƒˆã«å¤‰æ›"""
    file_patterns = ["**/*.py", "**/*.md", "**/*.txt"]
    all_files = []
    for pattern in file_patterns:
        all_files.extend(glob.glob(os.path.join(local_path, pattern), recursive=True))
    docs = []
    for i, file in enumerate(all_files):
        print(f"[{i+1}/{len(all_files)}] ğŸ”„ å‡¦ç†ä¸­: {file}")
        try:
            loader = TextLoader(file, encoding="utf-8")
            docs.extend(loader.load())
        except Exception as e:
            print(f"âš ï¸ èª­ã¿è¾¼ã¿å¤±æ•—: {file} ({e})")
    return docs

def safe_remove_dir(path: str):
    try:
        shutil.rmtree(path)
        print(f"âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤æˆåŠŸ: {path}")
    except Exception as e:
        print(f"âš ï¸ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤å¤±æ•—: {e}")

def setup_retriever(
    persist_dir: str,
    embedder: Embeddings,
    local_path: str = "./",
    reset: bool = False,
) -> VectorStoreRetriever:
    """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èµ°æŸ»ã—ã¦Retrieverã‚’æ§‹ç¯‰ã€‚å¿…è¦ã«å¿œã˜ã¦DBå‰Šé™¤"""
    if reset and os.path.exists(persist_dir):
        # Chroma DB ã‚’ä½¿ã£ã¦ã„ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ãŒã‚ã‚‹ã¨å‰Šé™¤ã§ããªã„ãŸã‚ã€å…ˆã«é–‹ã„ã¦é–‰ã˜ã‚‹
        try:
            # ä¸€åº¦ãƒ­ãƒ¼ãƒ‰ã—ã¦é–‹æ”¾
            tmp_db = Chroma(
                persist_directory=persist_dir,
                embedding_function=embedder,
                client_settings=get_shared_settings(persist_dir)
            )
            # æ˜ç¤ºçš„ã«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é–‰ã˜ã‚‹
            if hasattr(tmp_db, "_client") and hasattr(tmp_db._client, "reset"):
                tmp_db._client.reset()  # Chromaã®clientã®æ¥ç¶šã‚’ãƒªã‚»ãƒƒãƒˆ
                print("ğŸ”„ DBæ¥ç¶šã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸã€‚")

            del tmp_db
            tmp_db = None
            gc.collect()
            time.sleep(5)  # Windowsç”¨ãƒ•ã‚¡ã‚¤ãƒ«è§£æ”¾å¾…æ©Ÿ
        except Exception as e:
            print(f"âš ï¸ DBåˆæœŸåŒ–å‰ã®é–‹æ”¾ã«å¤±æ•—: {e}")
        
        safe_remove_dir(persist_dir)

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ & åˆ†å‰²
    raw_docs = load_documents(local_path)
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    split_docs = splitter.split_documents(raw_docs)

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆæƒ…å ±ã‚‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿½åŠ 
    structure_text = "[PROJECT_STRUCTURE]\nã“ã‚Œã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆæƒ…å ±ã§ã™ã€‚\n" + get_project_structure(local_path)
    if structure_text.strip():
        structure_doc = Document(
            page_content=structure_text,
            metadata={"source": "project_structure.txt", "type": "structure"}
        )
        structure_splits = splitter.split_documents([structure_doc])
        split_docs.extend(structure_splits)
        print(f"âœ… æ§‹æˆæƒ…å ±ã‚‚ retriever ã«å«ã‚ã¾ã—ãŸã€‚")

    # ãƒ™ã‚¯ãƒˆãƒ«DBç™»éŒ²
    #vectordb = Chroma.from_documents(split_docs, embedding=embedder, persist_directory=persist_dir)
    vectordb = Chroma(
        persist_directory=persist_dir,
        embedding_function=embedder,
        client_settings=get_shared_settings(persist_dir)
    )
    vectordb.add_documents(split_docs)
    vectordb.persist()
    return vectordb.as_retriever()
