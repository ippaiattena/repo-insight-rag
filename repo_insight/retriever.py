import glob
from langchain_core.documents import Document
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain.vectorstores.base import VectorStoreRetriever
from langchain.embeddings.base import Embeddings
import shutil
import os


def load_documents(local_path: str) -> list[Document]:
    """æŒ‡å®šãƒ‘ã‚¹é…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€Documentãƒªã‚¹ãƒˆã«å¤‰æ›"""
    file_patterns = ["**/*.py", "**/*.md", "**/*.txt"]
    all_files = []
    for pattern in file_patterns:
        all_files.extend(glob.glob(os.path.join(local_path, pattern), recursive=True))
    docs = []
    for i, file in enumerate(all_files):
        print(f"[{i+1}/{len(all_files)}] ğŸ”„ å‡¦ç†ä¸­: {file}")
        try:
            loader = TextLoader(file, encoding="utf-8")
            docs.extend(loader.load())
        except Exception as e:
            print(f"âš ï¸ èª­ã¿è¾¼ã¿å¤±æ•—: {file} ({e})")
    return docs


def setup_retriever(
    persist_dir: str,
    embedder: Embeddings,
    local_path: str = "./",
    reset: bool = False,
) -> VectorStoreRetriever:
    """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èµ°æŸ»ã—ã¦Retrieverã‚’æ§‹ç¯‰ã€‚å¿…è¦ã«å¿œã˜ã¦DBå‰Šé™¤"""
    if reset and os.path.exists(persist_dir):
        shutil.rmtree(persist_dir)

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ & åˆ†å‰²
    raw_docs = load_documents(local_path)
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    split_docs = splitter.split_documents(raw_docs)

    # ãƒ™ã‚¯ãƒˆãƒ«DBç™»éŒ²
    vectordb = Chroma.from_documents(split_docs, embedding=embedder, persist_directory=persist_dir)
    return vectordb.as_retriever()
